TACE-Scripts Tutorial
=======

This section introduces some commonly used scripts for training, inference, and various utility tasks.
The supported scripts are:

- **tace-train**
- **tace-eval**
- **tace-export**
- **tace-convert**
- **tace-clean**
- **tace-graph**
- **tace-split**


.. note::

   All scripts support the ``-h`` option to display all available command-line arguments and usage instructions.

Among them, we focus on the first four scripts, which are the most basic and frequently used:

1. **tace-train**  
   This script is used to start model training. Users can configure training parameters and initiate the training process.

.. code-block:: bash

   tace-train -cn *.yaml

   # In particular, if your YAML file is named 'tace.yaml', you can directly use:
   tace-train 


2. **tace-eval**  
   After training is complete, this script evaluates the model and produces an inference result file.

.. code-block:: bash

   # You should at least include -i and -m options
   # -i specifies the input file (ase.io.read) for inference
   # -m specifies the model checkpoint file (.ckpt, .pt and .pth)
   # If you want to test, add --test, 
   # don't forget to specify your key, if your property key is not the default value
   # For other options, use -h

   tace-eval -i *.xyz -m *.ckpt

3. **tace-export**  
   Conversion of model formats  

- **ckpt**: The `.ckpt` file is a checkpoint saved by the Lightning callback. It contains not only the model but also 
all related metadata, allowing the training process to be resumed.  
- **pt/pth**: Contains only the model itself without additional data. It is used for inference and pretraining.

.. code-block:: bash

   # Currently, only the use of LAMMPS requires mandatory model export.  
   # For other backends, you may also export the model if you wish to reduce its storage size.
   tace-export -m *.ckpt --dtype float32 --backend lammps --device cuda


4. **tace-convert**  
   This script is used to modify the internal architecture of a trained model. 

.. code-block:: bash
   # It is mainly employed to convert, for example, a direct model into a conservative model,  
   # and to modify the model's internal statistical information (such as isolated atomic energy, scale, shift, etc.).
   # This finetuning feature is still under development and is only recommended for those who are interested in experimenting with it.  
   # Its effectiveness is not guaranteed.

   tace-convert -m *.ckpt --type dir2con

5. **tace-clean**  

.. code-block:: bash
   
   # This script is used to clean the output files generated by TACE
   tace-clean

6. **tace-split**  

.. code-block:: bash
   
   # This script is used to split the dataset
   # -n specify the number of configurations in each set
   tace-split -i *.xyz -n 800 100 100 --seed 42

7. **tace-graph**  
This script is mainly used for pre-building graphs for large datasets (>1 million).  
It is particularly useful if you might repeat training. Otherwise, each time you retrain, you would need to rebuild the graph.  
**The input file must be exactly the same as the one used for training.**  
When using this script, it will stop immediately after building the graph. In practical use with `tace-train`, generally, 
if the dataset storage mode is `lmdb` and the specified `shard_dirs` contain pre-built graphs, it will automatically read them and skip the graph-building phase.

.. code-block:: bash  
   tace-graph -cn *.yaml
